<!doctype html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="description" content="Learn Morse Code">
    <meta name="keywords" content="chatbot, morse code">
    <link href="https://fonts.googleapis.com/css?family=Times+New+Roman" rel="stylesheet">
    <link href="style/research.css" rel="stylesheet">
    <link rel="icon" href="data:;base64,=">
    <title>Edge Detection Concepts</title>
  </head>
  <body>
    <h1>Differential Equations and Edge Detection</h1>
    <div class="text">
        Differential equations have a wide variety of applications. This project focuses on the application of derivatives on edge detection algorithms. Some of the most common edge detection algorithms use first order and second order derivatives on images to create a map of edges. We will be going into how these edge detection algorithms implement differential equations to calculate the edges of an image. The algorithms that will be discussed in this project are Sobel, Prewitt, Laplacian, and an application of these using Canny Edge Detection.
    </div>
    <div id="toc_container">
      <p class="toc_title">Contents</p>
      <ul class="toc_list">
        <li>1. <a href="#background">Background</a>
          <ul>
            <li>1.1 <a href="#intensity">Image Intensity</a></li>
            <li>1.2 <a href="#vectors">Image Vectorspace</a></li>
            <li>1.3 <a href="#gradient">Gradient Vectors</a></li>
            <li>1.4 <a href="#convolution">Matrix Convolution</a></li>
            <li>1.5 <a href="#gaussian">Gaussian Smoothing</a></li>
          </ul>
        </li>
        <li>2. <a href="#edges">Edge Detection Algorithms</a></li>
          <ul>
            <li>2.1 <a href="#prewitt">Prewitt</a></li>
            <li>2.2 <a href="#sobel">Sobel</a></li>
            <li>2.3 <a href="#laplacian">Laplacian</a></li>
            <li>2.4 <a href="#canny">Canny</a></li>
          </ul>
        <li>3. <a href="#applications">Applications</a></li>
          <ul>
            <li>3.1 <a href="#recognition">Object Recognition and Detection</a></li>
          </ul>
        <li>4. <a href="#example">Example</a></li>
        <li>5. <a href="#reference">References</a></li>
      </ul>
    </div>
    <div class="Paper" id="Background">
      <a id="background"><h2>1. Background</h2></a>
      <p class="text">
        Before we begin talking in depth about the edge detection algorithms, we will first explore some basic background knowledge required to understand the concepts used in this project. Specifically, we will go over how images can be represented as a 2 dimensional matrix of vectors, how the intensity of colors can be calculated and a gradient vector found based on the intensities to find the edges.
      </p>
    </div>
    <div class="Paper" id="Intensity">
      <a id="intensity"><h3>1.1 Image Intensity</h3></a>
      <div class="text">
        On a computer, images are represented as a discrete collection of pixels. These pixels represent a linear combination of Red, Green, and Blue values which can be used to produce different colors. However, when processing an image, especially for edges, it is often inefficient and not very useful to process all three values for each pixel. This is because even small images can often consist of at least tens of thousands of pixels; larger images can be made of millions of individual pixels. Processing three different value over potentially millions of pixels could end up being very costly and slow. As a result, the intensity of the image is often calculated and used instead. Although the exact definition for the intensity of a color can be a bit complex, for our purposes it suffices to think of it as the brightness of an color<sup>[<a href="#first">1</a>]</sup>. There are multiple ways of calculating this value, listed below: 
        <p class="footer">Average intensities of each red green blue value<sup>[<a href="#third">3</a>]</sup></p>
        \[ \frac{red + green + blue}{3} \]
        <p class="footer">Formula for Luminance<sup>[<a href="#fourth">4</a>]</sup></p>
        \[ 0.299*red + 0.587*green + 0.114*blue \]
        <br>
        These formulas result in a single value based on the amount of red, green, or blue the pixel has. The result is a shade of gray of the original image - another way to think of it is that all color data has been stripped and replaced with a single value of how bright the pixel is. This will improve processing time and efficiency while still being able to detect changes between pixels. However, there is still the issue of the loss of data. Although this is usually not a problem, in some cases it can lead to unexpected results. The main problem that may arise is that different colors can have the same intensity - especially when using the first equation. In edge detection, this can possibly lead to the absence of an edge when in fact there is one. While this can be prevented by using all three values instead of the intensity, it is often not necessary as the cases are rare and the edges themselves not strong. Now that we have gone over how the intenstiy of an image can be calculated and used, next we will talk about how vectors can be calculated from images.
      </div>
    </div>
    <div class="Paper" id="Vector">
      <a id="vectors"><h3>1.2 Images as a Matrix of Vectors</h3></a>
      <div class="text">
        Images are commonly stored on computers as an array of pixels. Although on software they can be stored as a 1 dimensional array, it would be more accurate to think of these arrays as representing a 2 dimensional image. As a 2-Dimensional image, each pixel would have 8 surrounding neighbor pixels (North, North East, East, South East, South, South West, West, and North West). In each direction we can calculate a scalar quantity from the pixel - either an RGB value or its corresponding intensity. In otherwords, we have both a direction, and magnitude - thus we can calculate vector quantities for every pixel in an image. If we extend that principle to the whole area of pixels, can think of the Image as a 2D vectorspace. Furthermore, we can represent this image as a 2D matrix. Note, however, that this matrix will be very large - images are often a few thousands pixels wide by a few thousand pixels long, resulting in a total number of pixels to the order of millions. Now we can perform operations such as finding the gradient vector at a certain point, or perform convolution between the image matrix and another operator matrix. Let us first consider finding the gradient of a matrix.
      </div>
    </div>
    <div class="Paper" id="Gradient">
      <a id="gradient"><h3>1.3 Gradient Vectors</h3></a>
      <div class="text">
        The gradient vector is similar to the derivative of a vector. In the case of images we are working with a 2-Dimensional space, so we can think of the gradient vector in terms of x and y. 
        \[ \vec{\nabla}f(x, y) = \langle{\frac{\partial f}{\partial x}, \frac{\partial f}{\partial y}}\rangle \]
        This is our first use of differential equations with images, so it is worth our time to delve a bit further. In essence edge detection requires us to find the difference in intensity between a pixel and its surrounding neighbor pixels. The gradient vector allows to do just that on an image, which is why it is of much importance to us. However, the equation introduced above models the gradient vector on a continuouos space - whereas on computers images are stored as a discrete 2-Dimensional collection of pixels. Thus a separate equation must be considered for the discrete case<sup>[<a href="#fifth">5</a>]</sup>.
        \[ \frac{\partial f}{\partial x} = \frac{I(x + 1, y) - I(x - 1, y)}{2} \]
        \[\frac{\partial f}{\partial y} = \frac{I(x, y + 1) - I(x, y - 1)}{2} \]
        I represents the 2-D image matrix, and the (x, y) refer to the pixel located at the point (x, y) on the image. Once the gradient vector is determined, some other properties can also be calculated. Specifically, the magnitude and angle of the gradient can be calculated. Because the gradient is essentially a derivative, its magnitude quantifies how quickly the image is changing at that point<sup>[<a href="#fifth">5</a>]</sup>. In other words, the magnitude is a measure of how strong or defined an edge is compared with its neighboring pixels. The angle of the gradient will be normal to the edge, and so it can be used to calculate the direction of the edge.
        <br>
        <p class="footer">Magnitude</p>
        \[ \| \mathbf{G} \| = \sqrt{{G_x}^2 + {G_y}^2} \]
        <p class="footer">Angle</p>
        \[ \theta = \arctan{\frac{G_y}{G_x}} \]
      </div>
    </div>
    <div class="Paper" id="Convolution">
      <a id="convolution"><h3>1.4 Matrix Convolution</h3></a>
      <div class="text">
        Matrix convolution involves the multiplication of a matrix against another matrix<sup>[<a href="#second">2</a>]</sup>. In this case we use special operators that can be multiplied across the whole image matrix to calculate the gradient vectors of the image. One of the main problems to consider when conducting convolution with matrices, are the edges. Let's say a 3x3 square matrix serves as an operator for matrix convolution with a larger 100x100 matrix. Along the edges there may not be any values to multiply with. This can be accounted for in a couple of different ways. One method is to pad the edges of the 100x100 matrix with a border of zeroes one pixel deep. This would allow for convolution against the edges of the matrix, while not changing the overall values. Another way to handle this is to not start from the edge. This would result in a smaller size matrix, but the data will be accurate. This project uses the first method, and pads matrices before convolution.
      </div>
    </div>
    <div class="Paper" id="Gaussian">
      <a id="gaussian"><h3>1.5 Gaussian Smoothing</h3></a>
      <div class="text">
        One of the main hurdles in image processing is dealing with noise in an image. In images, noise is often defined as a random variation of brightness or color that is not found in the original object being captured<sup>[<a href="#eleven">11</a>]</sup>. Although there are many types of noise, in general noise tends to show up as small white dots that cover an image. The presence of noise can make it difficult to process an image because it causes portions of the image to be left out. One of the main ways to lessen the effects of noise is to apply a smoothing, or blurring, filter on an image. One common smoothing filter used is the Gaussian. Gaussian smoothing uses Gauss' equation in 2-Dimensions to weight the image according to a normal distribution. This gets rid of noise because it reduces the variation about the center of the image. 
        <p class="footer">2D Gaussian<sup>[<a href="#twelve">12</a>]</sup></p>
        \[ G = \frac{1}{2\pi\sigma^2} e^{-\frac{x^2 + y^2}{2\sigma^2}} \]
        The larger the sigma value, the greater the standard deviation meaning that more of the image is weighted. This translates to a blurrier image. The x, y coordinates are based on the size of the filter to be applied to the image. For example, a 3x3 filter would have a domain centered at (0, 0), with the top left coordinate at (-1, 1). The resulting filter is then normalized against the sum of all Gaussian values, and then applied against the image using convolution.
        <p class="footer">3x3 Gaussian filter with sigma of 1</p>
        <div class="Operator">
          <div>.075</div>
          <div>.123</div>
          <div>.075</div>
          <div>.123</div>
          <div>.204</div>
          <div>.123</div>
          <div>.075</div>
          <div>.123</div>
          <div>.075</div>
        </div>
      </div>
    </div>
    <div class="Paper" id="Edges">
      <a id="edges"><h2>2. Edge Detection Algorithms</h2></a>
      <div class="text">
        Now that we got the basics out of the way, we can start discussing how these edge detection algorithms really work. We will start with the basic Prewitt operator, move on to the Sobel operator, then the Laplacian operator, before closing with the canny edge detection algorithm.
      </div>
    </div>
    <div class="Paper" id="Prewitt">
      <a id="prewitt"><h3>2.1 Prewitt Edge Detection</h3></a>
      <div class="text">
        The Prewitt operator was developed in 1970 by John Prewitt<sup>[<a href="#sixth">6</a>]</sup>. It is one of the more basic forms of edge detection, and involves the convolution of a pure first derivative operator on an image. There are two operators - one in the x direction and in the y direction. The matrix in the x direction is shown below, the y direction matrix would be the transpose of this one. As you can see, when the convolution is executed, pixels in the x or y directions will be subtracted to their respective opposite. This will give you the difference in intensity at each pixel. This is essentially a pure discrete representation of the gradient vector on the image. 
        <p class="footer">Prewitt Operator in the X direction</p>
        <div class="Operator">
          <div>-1</div>
          <div>0</div>
          <div>1</div>
          <div>-1</div>
          <div>0</div>
          <div>1</div>
          <div>-1</div>
          <div>0</div>
          <div>1</div>
        </div>
      </div>
    </div>
    <div class="Paper" id="Sobel">
      <a id="sobel"><h3>2.2 Sobel Edge Detection</h3></a>
      <div class="text">
        While the Prewitt operator will give you a map of all the differences, it does not handle noise very well. What this means is that the Prewitt operator is prone to returning false edges resulting in an inaccurate map. To avoid this issue, the Sobel-Feldman operator is commonly used instead. Researchers Irwin Sobel, and Gary Feldman introduced this operator as part of a talk in a larger convention in 1968<sup>[<a href="#seventh">7</a>]</sup>. Instead of taking the pure derivative of the pixels, Sobel weighted the neighbors to the East and West, and North and South directions by a factor of 2. As a result, the intensities of the pixels along the corners are not as important in the final result. Another way of thinking of this is that we are blurring the pixels in the corner while still taking them into account. As a result, noise is reduced and a more accurate edge map can be developed.
        <p class="footer">Sobel Operator in the X direction</p>
        <div class="Operator">
          <div>-1</div>
          <div>0</div>
          <div>1</div>
          <div>-2</div>
          <div>0</div>
          <div>2</div>
          <div>-1</div>
          <div>0</div>
          <div>1</div>
        </div>
      </div>
    </div>
    <div class="Paper" id="Laplacian">
      <a id="laplacian"><h3>2.3 Laplacian Edge Detection</h3></a>
      <div class="text">
      \[ \vec{\nabla}L(x, y) = \frac{\partial^2 L}{\partial x^2} + \frac{\partial^2 L}{\partial y^2} \]
        Shown above is the equation that represents the continuous second order derivative used as the basis for the Laplacian operator. The Laplacian operator uses second order derivatives to generate the edge map. Based on the original Laplace operator developed by Pierre-Simon de Laplace, the discrete matrix representation can be used to find edges in an image<sup>[<a href="#third">3</a>]</sup>. However, because this operator essentially detects changes in the changes of the image, it has the downside of being very sensitive to noise. To avoid this, the image is commonly blurred before processing to avoid returning unnecessary edges.
        <p class="footer">Laplacian Operator</p>
        <div class="Operator">
          <div>-1</div>
          <div>-1</div>
          <div>-1</div>
          <div>-1</div>
          <div>8</div>
          <div>-1</div>
          <div>-1</div>
          <div>-1</div>
          <div>-1</div>
        </div>
      </div>
    </div>
    <div class="Paper" id="Canny">
      <a id="canny"><h3>2.4 Canny Edge Detection</h3></a>
      <div class="text">
      The Canny Edge Detection algorithm builds on the Sobel operator to produce a better map of edges. Once an initial map of edges using the Sobel operator is formed, the edges are thinned through a non-maximum suppression algorithm. This algorithm only keeps the strongest edge and ignores all other weaker edges. Then through double thresholding, edges that are weaker than the lower threshold are filtered out while edges that are stronger than the higher threshold are highlighted. Finally, the edges that lie between the low and high thresholds are either filtered out or highlighted based on its surrounding pixels through hysteresis thresholding. In short, if a weak edge is connected to a strong edge then it is highlighted, and ignored otherwise.<sup>[<a href="#third">3</a>]</sup> The final result is a clear map of edges. Although this method was developed over 30 years age in 1986 by John F. Canny, it is still one of the more commonly used edge detection algorithms today<sup>[<a href="#eighth">8</a>]</sup>.
      </div>
    </div>
    <div class="Paper" id="Applications">
      <a id="applications"><h2>3. Applications of Edge Detection</h2></a>
      <div class="text">
        Calculating the edges of an image is an important first step in many different applications of computer vision. The map of edges often carries with them much important and useful data which can be used to classify and describe the image. This feature of the edges is often taken advantage of to build much more complex and helpful algorithms and technologies. One particularly common application of this can be found in object recognition and detection.
      </div>
    </div>
    <div class="Paper" id="Recognition">
      <a id="recognition"><h3>3.1 Object Recognition and Detection</h3></a>
      <div class="text">
        Object recognition and detection is a popular field of computer vision that has seen much use in many different fields. For example, many digital cameras use basic face detection algorithms to focus on and track faces when taking a picture. Another example can be seen in businesses like Tesla, which are experimenting on using object detection and recognition to develop self driving cars. Often, a major step in these algorithms is to generate the edges in the image among other features. Then this map of edges is compared with specific points found in hundreds or sometimes thousands of edges of known images. By comparing data such as the angle and magnitude of the edges with a database, computers can classify an image as an object within a specific confidence level<sup>[<a href="#ten">10</a>]</sup>. To handle this part of the computation, some type of neural network or machine learning algorithm is often used. Using only the edges will allow objects to be recognized despite having different lighting, or color. However, it is also important to check different transformations and sizes of the objects<sup>[<a href="#ninth">9</a>]</sup>.
      </div>
    </div>
    <div class="Paper" id="Example">
      <a id="example"><h2>4. Example implementations of edge detection</h2></a>
      <div class="text">
        <a href="https://outisnomore.github.io/image-processing">Go here for a sample implementation</a>
        <br>
        <a href="https://github.com/OutisNoMore/image-processing/blob/master/src/ImageToolKit.tsx">Go here to look at the code</a>
      </div>
    </div>
    <div id="references">
      <a id="reference"><h2>5. References</h2></a>
      <ol class="reference_list">
        <li>
          <p id="first">Fisher, Robert, et al. &quotPixel Values.&quot <cite>HIPR</cite>, <a href="https://homepages.inf.ed.ac.uk/rbf/HIPR2/value.htm">homepages.inf.ed.ac.uk/rbf/HIPR2/value.htm</a>. Accessed 10 April 2022.</p>
        </li>
        <li>
          <p id="second">Dachsbacher, Carsten, et al. &quotGPU Computing: Image Convolution.&quot <cite>Karlsruhe Institute of Technology</cite>, <a href="https://cg.ivd.kit.edu/downloads/assignment3_GPUC.pdf">cg.ivd.kit.edu/downloads/assignment3_GPUC.pdf</a>. Accessed 8 April 2022.</p>
        </li>
        <li>
          <p id="third">Jain, Ramesh, et al. <cite>Machine Vision.</cite> McGraw-Hill, 1995. <a href="https://cse.usf.edu/~r1k/MachineVisionBook/MachineVision.pdf">cse.usf.edu/~r1k/MachineVisionBook/MachineVision.pdf</a>. Accessed 10 April 2022</p>
        </li>
        <li>
          <p id="fourth">Chrishold, Wendy, and Ridpath, Chris. &quotTechniques for Accessibility Evaluation and Repair Tools.&quot <cite>W3C</cite>, <a href="https://w3.org/TR/AERT/#color-contrast">www.w3.org/TR/AERT/#color-contrast</a>. Accessed 10 April 2022.</p>
        </li>
        <li>
          <p id="fifth"> Jacobs, David. &quotImage Gradients.&quot <a href="https://cs.umd.edu/~djacobs/CMSC426/ImageGradients.pdf">www.cs.umd.edu/~djacobs/CMSC426/ImageGradients.pdf</a>. Accessed 9 April 2022.</p>
        </li>
        <li>
          <p id="sixth">Prewitt, J.M.S. &quotObject enhancement and extraction.&quot <cite>Picture Processing and Psychopictorics</cite>, 1970, pp. 75-149.</p>
        </li>
        <li>
          <p id="seventh">Sobel, Irwin. &quotAn Isotropic 3x3 Image Gradient Operator&quot Presentation at Stanford A.I. Project, 1968. <a href="https://www.researchgate.net/publication/239398674_An_Isotropic_3x3_Image_Gradient_Operator">researchgate.net/publication/239398674_An_Isotropic_3x3_Image_Gradient_Operator</a>. Accessed 10 April 2022.</p>
        </li>
        <li>
          <p id="eighth">Pound, Mike. &quotCanny Edge Detector - Computerphile.&quot <cite>YouTube</cite>, uploaded by Computerphile, 11 November 2015, <a href="https://youtube.com/watch?v=sRFM5IEqR2w">www.youtube.com/watch?v=sRFM5IEqR2w</a>. Accessed 10 April 2022.</p>
        </li>
        <li>
          <p id="ninth">James, Alex P. &quotEdge Detection for Pattern Recognition: A Survey.&quot <cite>arXiv,</cite> 2016, <a href="https://arxiv.org/ftp/arxiv/papers/1602/1602.04593.pdf">arxiv.org/ftp/arxiv/papers/1602/1602.04593.pdf</a>. Accessed 10 April 2022.</p>
        </li>
        <li>
          <p id="ten">Kalyani, B., et al. &quotSegmentation and Object Recognition Using Edge Detection Techniques.&quot <cite>International Journal of Computer Science &amp Information Technology</cite>, vol. 2, no. 6, 2010, <a href="https://airccse.org/journal/jcsit/1210ijcsit14.pdf">airccse.org/journal/jcsit/1210ijcsit14.pdf</a>. Accessed 13 April 2022.</p>
        </li>
        <li>
          <p id="eleven">Farooque, Mohd A., Rohankar, Jayant S. &quotSurvey on Various Noises and Techniques for Denoising the Color Image.&quot <cite>International Journal of Application or Innovation in Engineering and Management</cite>, vol. 2, no. 11, 2013, <a href="https://www.ijaiem.org/volume2issue11/IJAIEM-2013-11-24-070.pdf">www.ijaiem.org/volume2issue11/IJAIEM-2013-11-24-070.pdf</a>. Accessed 02 May 2022.</p>
        </li>
        <li>
          <p id="twelve">Fisher, Robert, et al. &quotGaussian Smoothing.&quot <cite>HIPR</cite>, <a href="https://homepages.inf.ed.ac.uk/rbf/HIPR2/gsmooth.htm">homepages.inf.ed.ac.uk/rbf/HIPR2/gsmooth.htm</a>. Accessed 02 May 2022.</p>
        </li>
      </ol>
    </div>
  </body>
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</html>
